{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "import h5py\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    " \n",
    "\n",
    "image_base_path = 'nabirds/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = \"nabirds/images.txt\"\n",
    "train_test_split = \"nabirds/train_test_split.txt\"\n",
    "classes = \"nabirds/classes.txt\"\n",
    "image_class_labels = \"nabirds/image_class_labels.txt\"\n",
    "\n",
    "def load_txt():\n",
    "    img_dic = {}\n",
    "    train_dic = {}\n",
    "    class_dic = {}\n",
    "    image_class_dic = {}\n",
    "    \n",
    "    with open(images) as img_object:\n",
    "        for line in img_object:\n",
    "            vals = line.replace('\\n', '').split(' ')\n",
    "            img_dic[vals[0]] = vals[1]\n",
    "            \n",
    "    with open(train_test_split) as train_object:\n",
    "        for line in train_object:\n",
    "            vals = line.replace('\\n', '').split(' ')\n",
    "            train_dic[vals[0]] = vals[1]\n",
    "            \n",
    "    with open(classes) as class_object:\n",
    "        for line in class_object:\n",
    "            vals = line.replace('\\n', '').split(' ')\n",
    "            key = vals[0]\n",
    "            vals.remove(key)\n",
    "            val = ' '.join(vals)\n",
    "            class_dic[key] = (val)\n",
    "            \n",
    "    with open(image_class_labels) as image_class_object:\n",
    "        for line in image_class_object:\n",
    "            vals = line.replace('\\n', '').split(' ')\n",
    "            image_class_dic[vals[0]] = vals[1]\n",
    "    \n",
    "    image_infos = []\n",
    "    for key in img_dic:\n",
    "        location = img_dic[key]\n",
    "        isTraining = bool(int(train_dic[key]))\n",
    "        class_name = class_dic[image_class_dic[key]]\n",
    "        image_infos.append([location, isTraining, class_name])\n",
    "    return image_infos\n",
    "\n",
    "def getTestInfo():\n",
    "    data = [d for d in load_txt() if d[1] == True]\n",
    "    return data\n",
    "\n",
    "def getTrainInfo():\n",
    "    data = [d for d in load_txt() if d[1] == False]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    # load the image\n",
    "    img = load_img(filename, target_size=(224, 224))\n",
    "    # convert to array\n",
    "    img = img_to_array(img)\n",
    "    # reshape into a single sample with 3 channels\n",
    "    img = img.reshape(224,224,3)\n",
    "    \n",
    "#     img = img.astype('float32')  \n",
    "#     img = img - [123.68, 116.779, 103.939]  \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = getTrainInfo()\n",
    "\n",
    "def load_images(infos):\n",
    "    images = []\n",
    "    i = 0\n",
    "    for info in infos:\n",
    "        if(i < 100):\n",
    "            images.append(load_image(image_base_path + info[0]))\n",
    "        else:\n",
    "            break\n",
    "        i = i + 1\n",
    "    return np.array(images)\n",
    "\n",
    "targets = [[target[2]] for target in train_info]\n",
    "\n",
    "targets = [targets[i] for i in range(100)]\n",
    "\n",
    "images = load_images(train_info)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "targets = np.array(encoder.fit_transform(targets).toarray())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 11s 2s/step - loss: 5.2042 - accuracy: 0.0227\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 11s 2s/step - loss: 5.1819 - accuracy: 0.0344\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 10s 2s/step - loss: 5.0752 - accuracy: 0.0069\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 11s 2s/step - loss: 4.7728 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 11s 2s/step - loss: 4.4132 - accuracy: 0.0464\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 10s 2s/step - loss: 4.3460 - accuracy: 0.0615\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 10s 3s/step - loss: 4.5989 - accuracy: 0.1134\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 10s 3s/step - loss: 4.5847 - accuracy: 0.0194\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 11s 2s/step - loss: 4.4275 - accuracy: 0.0221\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 10s 2s/step - loss: 4.1489 - accuracy: 0.0257\n"
     ]
    }
   ],
   "source": [
    "# define cnn model \n",
    "def define_model():  \n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224, 224, 3)))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.4))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(94, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "#     featurewise_center=True\n",
    "\t# specify imagenet mean values for centering\n",
    "# \tdatagen.mean = [123.68, 116.779, 103.939]\n",
    "\t# prepare iterator\n",
    "\ttrain_it = datagen.flow(images, targets)\n",
    "\t# fit model\n",
    "\tmodel.fit_generator(train_it, steps_per_epoch=len(train_it), epochs=10, verbose=1)\n",
    "\t# save model\n",
    "\tmodel.save('final_model.h5')\n",
    " \n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc3d87804d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[3.63455115e-07 5.60537633e-03 3.36288540e-05 2.03731470e-04\n",
      " 4.87527076e-12 2.43435238e-06 9.58965917e-04 4.52843233e-06\n",
      " 8.60197033e-05 7.00839706e-08 3.57615090e-06 1.13094866e-03\n",
      " 5.97946167e-01 1.47321924e-08 3.46806650e-09 6.50239934e-04\n",
      " 1.12975407e-07 4.39693504e-05 2.44007694e-08 3.65483034e-12\n",
      " 5.15235661e-05 2.86936793e-05 3.73611721e-04 6.40326820e-04\n",
      " 9.39968381e-11 8.16277979e-09 1.17346675e-08 8.53693753e-04\n",
      " 2.01977397e-04 1.79359540e-05 4.98255424e-04 3.54966323e-05\n",
      " 6.57565380e-08 4.50885971e-04 1.33444793e-08 1.63314233e-08\n",
      " 3.06000441e-01 7.00452673e-12 3.54027812e-04 6.49369849e-06\n",
      " 3.47381790e-10 2.36073261e-04 4.36309406e-08 3.08158263e-08\n",
      " 1.27707463e-05 7.76223260e-07 1.77521076e-06 3.73857262e-07\n",
      " 1.29590346e-03 4.77890061e-10 1.43615397e-10 1.90558946e-08\n",
      " 2.73998652e-04 5.33252287e-09 8.15668027e-05 1.51941558e-05\n",
      " 8.65102550e-07 1.26020021e-08 1.43042498e-03 1.78597759e-07\n",
      " 4.34419833e-10 2.55747636e-06 4.36153128e-11 7.61959609e-06\n",
      " 3.34938022e-06 2.70014536e-03 3.84352550e-09 1.41729133e-05\n",
      " 1.20760303e-12 4.78010764e-03 6.07623360e-06 4.91570536e-05\n",
      " 9.45742443e-12 3.99846378e-09 7.57618254e-05 1.75031244e-06\n",
      " 7.12699011e-06 2.20833444e-05 7.14804003e-07 6.92327740e-03\n",
      " 1.23565123e-08 8.65887632e-05 2.77823972e-04 1.71966144e-06\n",
      " 1.41481253e-08 7.19060190e-03 1.69319506e-07 7.80249229e-06\n",
      " 1.59804159e-07 3.32764714e-08 2.83521095e-09 5.66929877e-02\n",
      " 1.19955985e-05 1.60249358e-03]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction for a new image.\n",
    "\n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, target_size=(224, 224))\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 3 channels\n",
    "\timg = img.reshape(1, 224, 224, 3)\n",
    "\t# center pixel data\n",
    "\treturn img\n",
    " \n",
    "# load an image and predict the class\n",
    "def run_example():\n",
    "\t# load the image\n",
    "\timg = load_image('nabirds/images/0817/2d9d025b88c34a1ebf9eb88f21f23ad8.jpg')\n",
    "\t# load model\n",
    "\tmodel = load_model('final_model.h5')\n",
    "\t# predict the class\n",
    "\tresult = model.predict(img)\n",
    "\tprint(result[0])\n",
    " \n",
    "# entry point, run the example\n",
    "run_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
